# ARTS Week 1

## Algorithm
[Tow Sum](https://github.com/xuqingxin/leetcode/blob/master/Algorithms/0001-Two.Sum.md)


## Review
### 技术债就像是俄罗斯方块

原文链接：[Technical Debt Is Like Tetris](
https://medium.com/s/story/technical-debt-is-like-tetris-168f64d8b700)

文章一开始作者就说到，他很喜欢俄罗斯方块这个游戏。除了因为俄罗斯方块一直一来都是最好的游戏之一，更是因为它是对技术债的一个精妙的类比。

![少量的技术债是正常的，可控的](https://github.com/xuqingxin/arts/blob/master/images/Review1/1.png)

作者认为在俄罗斯方块中消除一行，就是交付一个简答功能。而交付一个复杂功能就需要消除多行（即需要多个简单功能共同组成一个复杂功能）。而技术债就是俄罗斯方块中被上面的方块覆盖住的空隙。

![被覆盖的空隙就是技术债](https://github.com/xuqingxin/arts/blob/master/images/Review1/2.png)

作者认为所有的代码都有技术债，这很正常。即使有空隙，你仍然可以继续玩俄罗斯方块。但是太多技术债会妨碍你在合理的时间内交付新的功能或者修复bug。这个问题并不能通过增加开发人员，或者更夸张地替换原来的开发人员来解决。它被称作技术债，在某种成度上，正是因为它需要偿还的。

偿还技术债让你保持竞争力。它让你在俄罗斯方块这个游戏中能继续玩下去。

![游戏结束](https://github.com/xuqingxin/arts/blob/master/images/Review1/3.png)

同经营一家企业一样，俄罗斯方块玩得时间越长，难度越大。随着时间推移，方块移动的速度越来越快，让人越来越难跟得上。

同经营一家企业一样，你永远不可能赢俄罗斯方块。它没有真实的终点线。你能做的就是控制自己输得尽量慢点。

同经营一家企业一样，玩俄罗斯方块的时候有太多空隙的话，会导致你很快输掉。

作者分享了一个通过偿还技术债而为企业带来巨大回报的故事。

作者的团队接手了一个新的任务，更新账单和发票逻辑来支持新价格体系。这个模块基本的功能就是查询客户的账户，计算他们的账单，然后把它发送给生成发票的API。他们花了点时间研究了现有的代码，发现这是一个单体模块，所有功能都集中在一起。没有测试，少得可怜的日志，几乎没有任何文档，还有一些没法解释的随机化处理。这些代码是5年前的一个共同创始人写的，自那之后唯一的改动就是很早之前入职的一位员工做的，现在他早已离开了公司。

因为业务需要，他们对它进行了重构，并且增加了很多必要的日志。后来他们发现这次重构修复了一个大bug。因为一个同事跟他们说寄给客户的发票金额意外地增加了好多。原因是原来的代码在超时后，默默地停止了客户后面的计费。因为没有日志，没人知道公司一直少收了客户的钱。这些钱加起来一年有1百万美元！

偿还技术债并不总是有回报

尽管上面的故事是一个真实的故事，但是偿还技术债并不会总是有如此高的收益，作者的团队只是运气比较好。

作者提到尽管他也希望能睿智地给出何时需要偿还技术债地建议，很不幸，答案是：这太复杂，永远都需要平衡。你可能有最整洁，测试充分的代码，但是你就是没有愿意付钱的客户。相反地，你公司发布的软件可能运行在混乱的代码上，却能让客户高兴，然后大把大把的挣钱。

不管如何，产品所有者和开发人员对什么是技术债必须有一个共同的认识。他们需要知道技术债永远都不能避免。毕竟，就像俄罗斯方块一样，在软件开发上，你永远都不会赢。

====================================================================

虽然我认为自己一直都很清楚什么是技术债，但是要让我来解释这个概念，还是有点费事的。看到这篇文章的标题，我就意识到自己对技术债的本质掌握得还是不够。俄罗斯方块这个比喻真实太精妙了。有了这个比喻，今后跟不懂技术的老板谈需要重构什么的，就有法宝了。只要老板玩过俄罗斯方块，他就能理解为什么技术人员那么喜欢重构，这样大家就能好好的谈话了。

这篇文章对我还有另一个启发。通过形象的比喻，可能把沟通做到事半功倍。很多时候我们掌握了对某项知识，要把它告诉其他人，如果只是做一个简单地知识搬运工，把这个知识的定义，原理将给其他人听，其他人因为可能没有这些背景知识，不一定能真正了解到你的意思。但是如果能用一个他很熟悉的事物，做一个类别，他就能很容易的知道这个新知识了。

我们要争取做一个有智慧的人，而不仅仅是一个有学问的人。


## Tip
### Linq Distinct()方法执行逻辑

这周需要对一个数组中的对象进行去重操作。

一般有2个办法：
1. 使用一个Set，重写Equals()和GetHashCode()方法，利用Set不能保存相同对象的特性，过滤相同的对象。
2. 在C#中使用Linq的Distinct()方法。Distinct()方法有个重载函数，可以增加IEqualityComparer参数，对于自定义对象来说再合适不过了。

因为不想再增加一个Set变量，把数组导入Set后再导出，我想直接使用Distinct()方法。另外，在Java中我做过类似的操作，排序的时候增加一个自定义的Comparator，就可以实现自定义排序结果了。

按照接口说明，我实现了IEqualityComparer的两个接口Equals()和GetHashCode()。

```C#
public bool Equals(T x, T y)
{
    // 根据业务逻辑返回
}

public int GetHashCode(T obj)
{
    return obj.GetHashCode();
}
```

但是这样一段看似平凡的代码就是不起作用。明明数组里有2个对象是一样的，就是不能去重，运行后的结果还是2个。

难道Distinct()方法没用？不可能啊，如果是这样，微软早就修复这么明显的bug了。既然对象不行，那就用基础数据类型试试看。

把数字中的对象换成整数后，运行代码发现结果如预期的样子，重复的被去掉了。这就奇怪了，只是把对象改成了整形，就可能，难道重载方法不能使用在对象上？这个也不太可能。

既然不知道问题，就把更多信息打印出来。我们在GetHashCode()方法中，把返回值打印出来，发现整数的值都是一样的！在把数组中的对象运行一遍，发现两个逻辑上一样的对象，GetHashCode()返回的值是不一样的。

由此我们猜测Distinct()的执行逻辑如下：
##### 1. 先执行GetHashCode()，如果hashCode不一致，直接返回，不会执行Equals()方法
##### 2. 对于相同hashCode的对象，执行Equals()，判断是否有相同的对象，如果有则过滤掉

后来把代码改成GetHashCode()直接返回0，在对象数组上调用Distinct()，重复对象就被过滤掉了。
```C#
public bool Equals(T x, T y)
{
    // 根据业务逻辑返回
}

public int GetHashCode(T obj)
{
    return 0;
}
```


## Share
### SlimTrie: 单机百亿文件的极致索引-设计篇

原文链接：
[https://openacid.github.io/tech/algorithm/slimtrie-design](
https://openacid.github.io/tech/algorithm/slimtrie-design)

文章首先提出了项目的目标：单机实现百亿文件的索引

接着简单介绍了常见的2层存储体系：
* 上传索引主要负责sharding，将查询路由到一个独立的服务器
* 下层负责具体的查询

![2层存储体系](https://github.com/xuqingxin/arts/blob/master/images/Share1/1.png)

在作者的设计中, 上层是一个百万级别的sharding, 下层直接是存储服务器, 存储服务器负责索引整机的文件. 这样, 上层sharding 的量级不会很大, 整个系统设计的核心问题就落在了单机的文件索引设计上。

剥去系统架构层面的组件, 剩下的就是单机上文件定位的问题。

作者先介绍了两种经典的索引结构设计方案，Hash Map和基于树的索引，但是这两种方案都有一个无法避免的问题：key的数量快速增长时，它们对内存空间的需求会变的非常巨大。这两种索引结构首先都会存储全量的key信息，假设key的平均长度是1KB，以100TB 的磁盘为例，可以存储1亿个10KB的小文件。那么仅这些key的索引就有10,000GB。这是完全无法接受的内存开销。

然后作者提出了他们的设计：SlimTrie索引。

如果要索引n个key, 那至少需要log2(n)个bit, 才能区分出n个不同的key。如果一共有n个key, 因此理论上所需的内存空间最低是log2(n)* n，这个就是作者空间优化的目标。在这个极限中，key的长度不会影响空间开销，而仅仅依赖于key的数量，这也是要达到的一个目标: 允许很长的key出现在索引中而不需要增加额外的内存。

实际上在实现时限制了n的大小，将整个key的集合拆分成多个指定大小的子集，这样有2个好处：n和log2(n)都比较确定，容易进行优化，占用空间更小，因为：a * log(a) + b * log(b) < (a+b) * log(a+b)。我们最终达到每个文件的索引均摊内存开销与key 的长度无关：

每条索引一共10byte，其中：6 byte是key的信息：4 byte是value: offset;

## SlimTrie 的设计
* 静态数据索引

> 数据生成之后在使用阶段不修改, 依赖于这个假设我们可以对索引进行更多的优化: 预先对所有的key 进行扫描, 提取特征, 大大降低索引信息的量。

> 在存储系统中, 需要被索引的数据大部分是静态的: 数据的更新是通过Append 和Compact 这2 个操作完成的. 一般不需要随机插入一条记录.

* SlimTrie 保证存在的key 被正确的定位, 但被索引到的key 不一定存在

> 索引的目的在于快速定位一个对象所在的位置范围, 但不保证定位到的对象一定存在，就像Btree 的中间节点, 用来确定key 的范围, 但要查找的key 是否真的存在, 需要在Btree 的叶子节点(真实数据)上来确定。

* SlimTrie 支持顺序查找和遍历key

> 索引很多情况下需要支持范围查询，SlimTrie 作为索引的数据结构，一定是支持顺序遍历的特点。SlimTrie 在结构上与树形结构有相似点，顺序遍历的实现并不难。

* SlimTrie 的内存开销只与key 的个数n 相关，不依赖于key 的长度k

* SlimTrie 支持最大16KB 的key

* SlimTrie 查询速度要非常快

假设n 个key ，每个key 的长度为k ，各数据结构的特性如下表：
| |空间开销 |查询时|
|-|-|-|
|Hash Map|O(k * n)|O(k)|
|Skplist, B Tree|O(k * n)|O(k * log(n))|
|Trie|O(k * n)|O(k)|
|SlimTrie|O(n)|O(log(n))|


生成的SlimTrie 三个步骤
1. 用所有的key 创建一个标准的Trie 树, 然后在标准Trie 树基础上做裁剪，裁剪掉标准Trie 中无效的节点，将索引数据的量级从O(n * k)降低到O(n)
> 裁剪掉Trie 树中单分支节点，单分支节点对索引key 没有任何的帮助

2. Trie 的压缩, 通过一个compacted array 来存储整个Trie 的数据结构, 在实现上将内存开销降低
> 接下来还要在实现上压缩Trie 实际的内存开销。树形结构在内存中多以指针的形式来实现, 但指针在64 位系统上占用8 个字节, 相当于最差情况下, 内存开销至少为8*n ，这样的内存开销还是太大了，所以我们使用compacted array 来压缩内存开销。

* 
对小文件的优化, 将多个相邻的小文件用1 条索引来标识, 平衡IO 开销和内存开销 
> 索引的设计以降低IO 和降低内存开销为目的，这两方面有矛盾的地方, 如果要降低IO 就需要索引尽可能准确, 这将带来索引的容量增加。如果要减小索引的内存开销, 则可能带来不准确的对磁盘上文件的定位而导致额外的IO 。在做这个设计的时候, 有一个假设是, 磁盘的一次IO, 开销是差不多的, 跟这次IO 的读取的数据量大小关系不大，所以可以在一次IO 中读取更多的数据来有效利用IO 。


## SlimTrie索引测试

### 内存开销
索引内存占用对比图
![索引内存占用对比图](https://github.com/xuqingxin/arts/blob/master/images/Share1/2.png)

memory overhead 对比图
![memory overhead 对比图](https://github.com/xuqingxin/arts/blob/master/images/Share1/3.png)

### 查询性能
存在的key的查找耗时对比图(越小越优)：
![存在的key的查找耗时对比图](https://github.com/xuqingxin/arts/blob/master/images/Share1/4.png)

不存在的key的查找耗时对比图(越小越优)：
![不存在的key的查找耗时对比图](https://github.com/xuqingxin/arts/blob/master/images/Share1/5.png)

## 总结
作为索引，SlimTrie 的优势巨大，可以在1 GB 内存中建 立100TB 数据量的索引，空间节约惊人，令以往的索引结构望尘莫及；时间消耗上，SlimTrie 的查找性能与sorted Array 接近，超过经典的B-Tree 。抛下索引这个身份，SlimTrie 在各项性能方面表现依旧不俗，作为一个通用Key-Value 的数据结构，内存额外开销仍远远小于经典的map 和Btree 。